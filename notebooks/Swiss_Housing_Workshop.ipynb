{"cells":[{"cell_type":"markdown","metadata":{"id":"vN74WwKJ2-Zh"},"source":["_____\n","\n","<center><h1>Introduction to Data Science</h1></center>\n","\n","<center><a target=\"_blank\" href=\"https://learning.constructor.org/\"><img src=\"https://drive.google.com/uc?id=1wxkbM60NlBlkbGK1JqUypKL24RrTiiYk\" width=\"200\" style=\"background:none; border:none; box-shadow:none;\" /></a> </center>\n","\n","<p style=\"margin-bottom:1cm;\"></p>\n","\n","_____\n","\n","<center> <h2> Workshop  </h2> </center>\n","\n","<p style=\"margin-bottom:1cm;\"></p>\n","\n","_____\n","\n","<center>Constructor Learning, 2023</center>\n","\n","_____\n"]},{"cell_type":"markdown","metadata":{"id":"g7JnrSbCebp4"},"source":["Welcome to this Data Analytics workshop! We hope you enjoy it, but most importantly have fun.\n","\n","Here's what we will cover today:\n","\n","- Data Science Lifecycle\n","- Data Wrangling\n","- Exploratory Data Analysis\n","- Intro to Machine Learning"]},{"cell_type":"markdown","metadata":{"id":"hNVnJE-WegDI"},"source":["---\n","First let's talk about the lifecycle of a Data Science project."]},{"cell_type":"markdown","metadata":{"id":"z850UIV57ItT"},"source":["\n","\n","<a target=\"_blank\" href=\"https://learn.microsoft.com/en-us/azure/architecture/data-science-process/lifecycle\"><img src=\"https://learn.microsoft.com/en-us/azure/architecture/data-science-process/media/lifecycle/tdsp-lifecycle2.png\" width=\"800\" style=\"background:none; border:none; box-shadow:none;\" /></a>"]},{"cell_type":"markdown","metadata":{"id":"n2aUw4NV8Gys"},"source":["<center><h1>Live Coding</h1></center>"]},{"cell_type":"markdown","source":["This is a copy notebook (file) of the original version. For your progress to be saved, you can go to `File` and then `Save a copy in Drive`. This is optional"],"metadata":{"id":"OnmqHV_TMdmZ"}},{"cell_type":"markdown","metadata":{"id":"5NAk6TJ7WPPH"},"source":["---\n","### How are we going to start our workshop fun?? 🐍\n","\n","The most popular programming language used in Data Science is [Python](https://www.python.org/). It is one of the most accessible yet very powerful programming languages available. It has a simplified syntax, which gives emphasis on natural language, making it easier to learn and read.\n","\n","But a programming languages needs a place to be written and executed. Just like we need Google Docs to write a novel, we need a [Colab Notebook](https://research.google.com/colaboratory/faq.html) (Or Jupyter Notebook) to write our amazing code. That is precisely what you are using right now on your browser, a computational web session that allows you to input and output python code.\n","\n","It makes the job of exploring data a lot more fun! Let's get started!"]},{"cell_type":"markdown","metadata":{"id":"oMfpqeIsCdhh"},"source":["# Load Dependencies"]},{"cell_type":"markdown","metadata":{"id":"_o0uiOb7YekT"},"source":["---\n","Python code is very powerful, but there are many operations that can get tedious if we were to code them ourselves. \n","\n","That is why several amazing authors all over the world have created libraries that help us perform specific tasks more efficiently and with less lines of code.\n","\n","For this workshop we will use the following libraries:\n","- **Pandas**: the most important tool of a Data Scientist. It offers many tools for data manipulation and analysis.\n","- **Plotly**: an interacting graphing library that allows us to plot the data and create visuals.\n","- **Scikit-Learn**: Simple and efficient tools for predictive data analysis Accessible to everybody, and reusable in various contexts."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3971,"status":"ok","timestamp":1670512460617,"user":{"displayName":"Dominik Bacher","userId":"01686362987424895343"},"user_tz":-60},"id":"h-zuBSMA8bBk","outputId":"39b06064-a8db-490e-f1bd-ee6ceefd130a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pgeocode in /usr/local/lib/python3.8/dist-packages (0.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pgeocode) (1.21.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from pgeocode) (1.3.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from pgeocode) (2.23.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->pgeocode) (2022.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->pgeocode) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->pgeocode) (1.15.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->pgeocode) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->pgeocode) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->pgeocode) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->pgeocode) (1.24.3)\n"]}],"source":["# Some libraries do not come preinstalled in Google Colab, so we need to manually install \n","# them using the next line of code.\n","!pip install pgeocode"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uabSWzl3DAMY"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pgeocode\n","\n","import plotly.express as px\n","import plotly.graph_objects as go"]},{"cell_type":"markdown","metadata":{"id":"Ow-MXiWo0vtL"},"source":["# Data Wrangling"]},{"cell_type":"markdown","metadata":{"id":"DhCgU70-DDwh"},"source":["## Load Dataset"]},{"cell_type":"markdown","metadata":{"id":"xTViBxj_03MW"},"source":["---\n","Data can come from many different sources, and depending on the format it is in, the way to import it will vary. In the case of the \"Swiss Housing Prices dataset\"*, the data is stored in Google Drive as a `.csv` file. The next block of code will load the data to the notebook into a Pandas DataFrame object.\n","\n","\\*Data scraped by [Ansam Zedan](https://www.linkedin.com/in/ansam-zedan/) on the Homegate.ch website."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h4o-jbPbCepv"},"outputs":[],"source":["# Read the home price csv file from the URL\n","orig_url = \"https://drive.google.com/file/d/14a0l9bT9DLFqIu5rtyiTc9hLC555rvOz/view?usp=sharing\"\n","file_id = orig_url.split('/')[-2]\n","data_path='https://drive.google.com/uc?export=download&id=' + file_id\n","\n","df = pd.read_csv(data_path, index_col=0)\n","df"]},{"cell_type":"markdown","metadata":{"id":"wD7l8V7fBq0K"},"source":["---\n","The first method we will use on our newly created dataframe is `.info()`. Here we can get a first overview of the types of data we have, and if we have missing values."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FL86mZQRBpJN"},"outputs":[],"source":["df.info()"]},{"cell_type":"markdown","metadata":{"id":"aCD5f1dDW_au"},"source":["---\n","The price column is formatted with alphanumeric values. In order to properly do data exploration, we need to treat this column as an integer (number), so let's clean this entries using a Regular Expression (regex) so it only keeps the digits"]},{"cell_type":"code","source":["df[\"price\"]"],"metadata":{"id":"uMs7-VU9W9K_"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j4MDfeOoWv9o"},"outputs":[],"source":["df[\"price\"].sample(n=10).unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ryw8L1nLV9yt"},"outputs":[],"source":["df['price'] = df['price'].str.replace('[^0-9]', '')\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"eB6Kb7a_Xtr9"},"source":["---\n","Now we have only numeric values for the price column, but will it be treated as an integer, or will Pandas still interpret it as a string?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3qe9G-lYX2vV"},"outputs":[],"source":["df.info()"]},{"cell_type":"markdown","metadata":{"id":"u3UnJer_5k7-"},"source":["---\n","Even though we stripped the values of non-numerical characters, we still need to convert the data type so it can be interpreted as an integer. This way we can later take advantage of this for plotting and applying methods if needed."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NM38eGsiX5-J"},"outputs":[],"source":["df['price'] = df['price'].astype(int)\n","df.info()"]},{"cell_type":"markdown","metadata":{"id":"4GcHMYqzthLx"},"source":["---\n","Another column which should be numerical but it's being treated as an object (string) is the \"area_m2\" column. In this case it would be beneficial to also strip the \"m2\" out of the values and only keep the numbers.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z0qNjPG4teZv"},"outputs":[],"source":["df.head(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Slkv_fXIX57x"},"outputs":[],"source":["df['area_m2'] = df['area_m2'].str.split(' ').str[0]\n","df['area_m2'] = df['area_m2'].astype(float)\n","df.head(3)"]},{"cell_type":"markdown","metadata":{"id":"56L9HjdLBbSH"},"source":["---\n","When working with data, many times there will be missing values in some of the samples. This is a normal situation to encounter when analyzing the data and emphasizes the importance of knowing the data. \n","\n","There are several approaches to deal with missing values:\n","- Substitute the missing values with the mean, median, mode or arbitrary value.\n","- Drop the samples with missing data.\n","- Impute the missing values using Machine Learning."]},{"cell_type":"markdown","metadata":{"id":"PupqiNkMJzHg"},"source":["---\n","The column \"floors_num\" indicates the number of floors that the property has. There are many entries with missing values in this column. We can inspect the data to make a more educated inference of which value to assign to the rows with missing data.\n","\n","We can do this by visualizing the counts of each type of property and seeing that most of the properties with missing values are apartments, which most of the time only have one floor."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p34SRc10OEY5"},"outputs":[],"source":["print(f\"Missing values in 'floors_num': {df['floors_num'].isna().sum()}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nS-0l18U2RDG"},"outputs":[],"source":["def get_type_proportion(request):\n","    if request == \"Is Nan\":\n","        conditional = df['floors_num'].isna()\n","    elif request == \"1\":\n","        conditional = df['floors_num'] == 1\n","    elif request == \"More than 1\":\n","        conditional = df['floors_num'] > 1\n","\n","    s1 = df[conditional]['type'].value_counts()[0:5].sort_index()\n","    s2 = pd.Series([df[conditional]['type'].value_counts()[5:].sum()], index=[\"Other\"])\n","    return pd.concat([s1, s2], ignore_index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P5990qyyZBsd"},"outputs":[],"source":["fig, ax = plt.subplots(1, 3, figsize=(22,5))\n","\n","inspect_df = get_type_proportion(\"1\")\n","ax[0].pie(inspect_df, labels=inspect_df.index, autopct='%1.f%%', startangle=90)\n","ax[0].set_title(\"Properties With One Floor\", fontsize=18)\n","\n","inspect_df = get_type_proportion(\"More than 1\")\n","ax[1].pie(inspect_df, labels=inspect_df.index, autopct='%1.f%%', startangle=90)\n","ax[1].set_title(\"Properties With More Than One Floor\", fontsize=18)\n","\n","inspect_df = get_type_proportion(\"Is Nan\")\n","ax[2].pie(inspect_df, labels=inspect_df.index, autopct='%1.f%%', startangle=90)\n","ax[2].set_title(\"Properties With Missing Floor Number\", fontsize=18)\n","\n","fig.show();"]},{"cell_type":"markdown","metadata":{"id":"p3wGlc157gTD"},"source":["---\n","Looking at the distribution of the types of properties according to the amount of floor levels they have, we can make the following assumption: properties with one floor level are mostly Apartments (73%), so since the majority of properties missing this value are also Apartments (49%), it's more likely that they also have one floor level."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S_6UUqvbX55D"},"outputs":[],"source":["df['floors_num'] = df['floors_num'].fillna(1).astype(int)\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"JTM7osY9EOG5"},"source":["---\n","The \"floor\" column which represents the level the property is located at also has several missing values. We will infer that no given data means it is a Ground Floor property."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BN5FhBhlOv0U"},"outputs":[],"source":["print(f\"Missing values in 'floor': {df['floor'].isna().sum()}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sqYimhJZlxdG"},"outputs":[],"source":["# EXERCISE 1\n","# Fill the missing values of the 'floor' column with \"GF\"\n","         # <-- Your code here\n","df.tail()"]},{"cell_type":"markdown","metadata":{"id":"8yZUQceZFf-q"},"source":["---\n","For the \"last_refurbishment\" column, which states the year of the last remodeling, there are also missing values. We will infer that this is because the building has not been refurbished since its construction, and it makes sense to set the date as the year which it was built."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FdfjSOIdPZim"},"outputs":[],"source":["print(f\"Missing values in 'last_refurbishment': {df['last_refurbishment'].isna().sum()}\")"]},{"cell_type":"code","source":["df[\"year_built\"]"],"metadata":{"id":"Jq0EWR6PUE-Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wr48psVMp00y"},"outputs":[],"source":["# EXERCISE 2\n","# Fill the missing values in the column 'last_refurbishment' with the values from the column 'year_built'\n","       # <--- Your code here\n","df"]},{"cell_type":"markdown","metadata":{"id":"x8km0RwoZkaS"},"source":["## Basic feature extraction"]},{"cell_type":"markdown","metadata":{"id":"PkdkUv_KCAdu"},"source":["--- \n","From data we already have, we can create new features. For example, using the area of the property and the price, we can also get the price per square meter."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SzGx3B2jCN9z"},"outputs":[],"source":["df = df[df[\"area_m2\"].notna()].copy()\n","df[\"price_sqm\"] = df['price'] / df['area_m2']\n","df[\"price_sqm\"] = df[\"price_sqm\"].astype(int)\n","print(df.shape)\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"Avp-_0x-B-zM"},"source":["---\n","We can get a few more features from the address column: like separating the zip code and the city, and even getting the coordinates for each property."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nu_PU4b7X52P"},"outputs":[],"source":["for address in df['address'].sample(n=20).unique():\n","  print(address)"]},{"cell_type":"markdown","metadata":{"id":"po5gDSCYQjIJ"},"source":["---\n","We see that some addresses only contain the zip code and city, but others also contain the full address. Let's extract these values."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OiixcO9oX5xT"},"outputs":[],"source":["def extract_zip_city(address):\n","    if ',' in address:\n","        zip_and_city = address.split(', ')[1]\n","        zip_code = zip_and_city.split(' ')[0]\n","        city = zip_and_city.split(' ')[1]\n","    else:\n","        zip_and_city = address\n","        zip_code = zip_and_city.split(' ')[0]\n","        city = zip_and_city.split(' ')[1]\n","    return pd.Series([zip_code, city])\n","\n","df[['zip_code', 'city']] = df['address'].apply(extract_zip_city)\n","df"]},{"cell_type":"markdown","metadata":{"id":"CMCCuLdCQw6y"},"source":["---\n","Using the library `pgeocode`, which we installed at the beginning of the notebook, we can use the zip code number to get the name of the canton and the coordinates we will later use."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W2_DFMYxnG0N"},"outputs":[],"source":["pgeocode_nomi = pgeocode.Nominatim('ch')\n","pgeocode_nomi.query_postal_code(\"8134\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GfdlIkJUqvDm"},"outputs":[],"source":["def add_canton(zip_code):\n","    zip_info = pgeocode_nomi.query_postal_code(zip_code)\n","    return zip_info[\"state_name\"]\n","\n","df[\"canton\"] = df[\"zip_code\"].apply(add_canton)\n","df.head(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yD6y2JV6sNbS"},"outputs":[],"source":["# EXERCISE 3\n","def add_coordinates(zip_code): \n","    zip_info = pgeocode_nomi.query_postal_code(zip_code)\n","    # Assign two variables called 'latitude' and 'longitude' with the corresponding keys from the 'zip_info' data\n","    latitude =  #<-- Your code here\n","    longitude =  #<-- Your code here\n","    return pd.Series([latitude, longitude])\n","\n","df[[\"lat\", \"lon\"]] = df[\"zip_code\"].apply(add_coordinates)\n","df.head(3)"]},{"cell_type":"markdown","metadata":{"id":"0zrz3xinRUL7"},"source":["--- \n","We no longer need the full address, so we can drop this column."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZmXWDQG8ocxY"},"outputs":[],"source":["df = df.drop('address', axis=1)"]},{"cell_type":"markdown","metadata":{"id":"0ZNeUphoe6VA"},"source":["---\n","Now we have our final data frame which we will use to do analysis, gather insights and create a machine learning model!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZUWry9R_fFm0"},"outputs":[],"source":["df"]},{"cell_type":"markdown","metadata":{"id":"qMgTOqy-RhrS"},"source":["# Basic EDA (Exploratory Data Analysis)"]},{"cell_type":"markdown","metadata":{"id":"5PDBzCc-0o3R"},"source":["## Data Distribution "]},{"cell_type":"markdown","source":["<img src=\"https://pbs.twimg.com/media/E5ePcUdVkAEvEX6?format=jpg&name=small\" width=\"250\" style=\"background:none; border:none; box-shadow:none;\" />\n","\n","<img src=\"https://upload.wikimedia.org/wikipedia/commons/c/cc/Relationship_between_mean_and_median_under_different_skewness.png\" width=\"700\" style=\"background:none; border:none; box-shadow:none;\" />\n","\n"],"metadata":{"id":"UQ4ltFU0Cbhs"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FN7x4tli0oWE"},"outputs":[],"source":["fig, ax = plt.subplots(1, 2,figsize=(20,5))\n","\n","sns.histplot(data=df, x='price', kde=True, stat='density', ax=ax[0])\n","sns.histplot(data=df, x='area_m2', kde=True, stat='density', ax=ax[1])\n","\n","fig.suptitle('Density of Price and Area', fontsize=18)\n","fig.show();"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dbu45H0KUVEE"},"outputs":[],"source":["fig = px.histogram(df, x=\"price\",\n","                   marginal=\"box\",\n","                   hover_data=df.columns)\n","fig.update_layout(\n","    font={\"size\":17},\n","    title_text=\"Price Distribution on Histogram and Boxplot\", \n","    title_x=0.5,\n","    )\n","\n","fig.show()"]},{"cell_type":"markdown","source":["---\n","**Understanding Box Plots**"],"metadata":{"id":"D2gEPhd9jOVK"}},{"cell_type":"markdown","source":["<center><img src=\"https://miro.medium.com/max/9000/1*2c21SkzJMf3frPXPAR_gZA.png\" width=\"700\" style=\"background:none; border:none; box-shadow:none;\" /></center>"],"metadata":{"id":"FwABEXuMjDxM"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"26rBTP_hnHFq"},"outputs":[],"source":["fig = px.box(df, x=\"type\", y=\"price\") \n","fig.update_layout(\n","    font={\"size\":17},\n","    title_text=\"Boxplot Distribution Between Property Types\", \n","    title_x=0.5,\n","    )\n","fig.update_xaxes(tickangle=-45)\n","fig.show()"]},{"cell_type":"markdown","metadata":{"id":"y9m2YIRLQ8at"},"source":["## Scatter Plot"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qmWiebBvLdkG"},"outputs":[],"source":["fig = px.scatter(df, x=\"area_m2\", y=\"price\", color='type')\n","\n","fig.update_layout(\n","    font={\"size\":17},\n","    title_text=\"Correlation Between Property Area And Its Price\", \n","    title_x=0.5,\n",")\n","\n","fig.show()"]},{"cell_type":"code","source":["# EXERCISE 4\n","# Plot a scatter plot with the correlation between price and number of roooms\n","\n","fig =  #<-- Your code here\n","\n","fig.update_layout(\n","    font={\"size\":17},\n","    title_text=\"Correlation Between Property Number Of Rooms And Its Price\", \n","    title_x=0.5,\n",")\n","\n","fig.show()"],"metadata":{"id":"FlKuzF5Qo9fL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LhGjcE_OSD39"},"source":["## Viewing Variable Correlations in a Heatmap"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rPKGSB2FMTUe"},"outputs":[],"source":["corr_matrix = df.corr()\n","corr_matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0rso6ASfMocD"},"outputs":[],"source":["def trunc(values, decs=0):\n","    return np.trunc(values*10**decs)/(10**decs)\n","\n","trimask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n","\n","\n","fig = go.Figure()\n","fig.add_trace(\n","    go.Heatmap(\n","        x = corr_matrix.columns,\n","        y = corr_matrix.index,\n","        z = np.array(corr_matrix),\n","        text=trunc(np.array(corr_matrix), decs=2), texttemplate=\"%{text}\",\n","        colorscale = 'RdBu', ygap=1, xgap=1\n","    )\n",")\n","\n","fig.update_layout(\n","    title_text=\"Correlation Heatmap\", \n","    title_x=0.5,\n","    width=1000, \n","    height=600,\n","    xaxis_showgrid=False,\n","    yaxis_showgrid=False,\n","    yaxis_autorange='reversed'\n",")\n","\n","fig.show()"]},{"cell_type":"markdown","metadata":{"id":"svqkpr-QR4fa"},"source":["# More Visualizations"]},{"cell_type":"markdown","metadata":{"id":"GJsJg5fbR7dm"},"source":["## Mapping"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UdeCEvwgR2zj"},"outputs":[],"source":["fig = px.scatter_mapbox(\n","    df, \n","    lat=\"lat\", \n","    lon=\"lon\", \n","    hover_name=\"price\", \n","    color=\"canton\", \n","    size=\"price\",\n","    zoom=7, \n","    center={\"lat\":46.8182, \"lon\":8.2275}\n",")\n","\n","fig.update_layout(\n","    mapbox_style=\"carto-positron\", \n","    margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0}, \n","    height=600, \n","    font={\"size\":17}\n",")\n","\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"deUJOQNGESr8"},"outputs":[],"source":["# EXERCISE 5\n","df_map = df[df['price']<5000000]\n","\n","fig = px.scatter_mapbox(\n","    df_map, \n","    lat=\"lat\", \n","    lon=\"lon\", \n","    hover_name=\"price\", \n","    color=???,   #<--- Make the map show the color scale from the price values\n","    zoom=7, \n","    center={\"lat\":46.8182, \"lon\":8.2275},\n",")\n","\n","fig.update_layout(\n","    mapbox_style=\"carto-positron\", \n","    margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0},\n","    height=600, \n","    font={\"size\":17}\n",")\n","\n","fig.show()"]},{"cell_type":"markdown","metadata":{"id":"ihjT7uOeSR1M"},"source":["# Intro to Machine Learning"]},{"cell_type":"markdown","metadata":{"id":"NaU6n1g7GvOa"},"source":["## Further Data Cleaning"]},{"cell_type":"code","source":["fig, ax = plt.subplots(figsize=(10, 6))\n","ax.set_title('Distribution Of Price')\n","ax.boxplot(df['price'])\n","fig.show();"],"metadata":{"id":"ZYamuKBrsn9D"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yBZwJ2LdGui1"},"outputs":[],"source":["df = df[df['price']< 5000000].reset_index(drop=True)\n","#df = df[~df[\"year_built\"].isna()]\n","df.drop(['lat', 'lon', 'price_sqm'], axis=1, inplace=True, errors='ignore')\n","df"]},{"cell_type":"markdown","source":["---\n","Machine learning is the process of teaching a computer to learn patterns from data and then to apply those patterns to make preditions on new data. In traditional programming, you write rules to tell the computer exactly what to do. For example, if you want to write a program that converts miles to kilometers, you would write a function that computes the following equation:\n","\n","<span>\n","<img src=\"https://drive.google.com/uc?id=1aa50Dd83JwO7x_SOWbNckj2ThBOfVdeb\" width=\"40%\"/>\n","\n","\n","But in ML, instead of writing the rule, you provide the computer a lot of examples of input data as well as the desired output, say many samples miles to kilometer conversion data. Then let the computer learn the rule itself.\n","\n","\n","<img src=\"https://drive.google.com/uc?id=1sj2IeZGi9RI6VH-ZvFpFdS2fC6e3XO0R\" width=\"40%\"/>\n","</span>\n","\n","But there are many cases where the rules are not that simple. For example, this very dataset of housing prices takes into consideration many variables, and it would be very complicated to write a formula ourselves.\n","\n","ML is ideal for these types of problems, where you have lots of data that have complex relationships that would be very difficult for humans to manually create rules for."],"metadata":{"id":"_C6h5OMAuKFI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0ZmPkdN5hq43"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n","from sklearn.impute import KNNImputer\n","from sklearn import metrics\n","from sklearn.kernel_ridge import KernelRidge\n","from sklearn.ensemble import RandomForestRegressor"]},{"cell_type":"markdown","source":["---\n","Don't worry too much about the following code. There are several technicalities better saved for another time. The only important thing to understand is that we separate our data from the independent (x) and dependent variables (y), since we want the ML algorithm to learn the patterns from the independent variables that give the target output."],"metadata":{"id":"KRWWb_SQuGPO"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3bebPZFThN_N"},"outputs":[],"source":["X = df.drop(columns=['price'])\n","y = df['price']\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()\n","numeric_features = X_train.select_dtypes(exclude=['object']).columns.tolist()\n","categorical_transformer = Pipeline(steps=[\n","                                          (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n","                                          ])\n","numeric_transformer = Pipeline(steps=[\n","                                      (\"knn_imputer\", KNNImputer(n_neighbors=5)),\n","                                      (\"scaler\", MinMaxScaler())\n","                                      ])\n","preprocessor = ColumnTransformer(transformers=[\n","                                               (\"num\", numeric_transformer, numeric_features),\n","                                               (\"cat\", categorical_transformer, categorical_features)\n","                                               ])\n","\n","model = RandomForestRegressor(n_estimators=1000)\n","\n","pipeline_model = Pipeline(steps=[\n","                              (\"pre_process\", preprocessor), \n","                              (\"model\", model)\n","                              ])\n","\n","pipeline_model.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5gU_KiOe1gyx"},"outputs":[],"source":["pred = pipeline_model.predict(X_test)\n","\n","print('MAE', metrics.mean_absolute_error(y_test, pred))\n","print('R2 Score', metrics.r2_score(y_test, pred))"]},{"cell_type":"markdown","source":["---\n","Enter the values of a property you would like to predict its price for:"],"metadata":{"id":"sGlhR2CZKjYH"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ksmjvQ4kW5aS"},"outputs":[],"source":["# EXERCISE 6\n","\n","target_property = {\n","    'type' : ['Apartment'],\n","    'room_num' : [2.5],\n","    'floor' : [\"2\"],\n","    'area_m2' : [80],\n","    'floors_num' : [1],\n","    'year_built' : [1990],\n","    'last_refurbishment' : [2002],\n","    'zip_code' : [\"8003\"],\n","    'city' : [\"Zürich\"],\n","    'canton' : [\"Kanton Zürich\"],\n","}\n","\n","to_predict = pd.DataFrame(target_property)\n","to_predict[['area_m2', 'year_built', 'last_refurbishment']] = to_predict[['area_m2', 'year_built', 'last_refurbishment']].astype(float)\n","to_predict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yAXg4c7Unumt"},"outputs":[],"source":["pred = pipeline_model.predict(to_predict)\n","print(f\"The value of the property using the trained machine learning algorithm is of {round(pred[0])} CHF\")"]},{"cell_type":"markdown","source":["---\n","Congratulations! \n","\n","- You learned how to start a Data Science project.\n","- You learned how to do data wrangling to clean the data.\n","- You learned how to do exploratory data analysis and visualize insights with plots.\n","- And you trained a Machine Learning Algorithm that allows user to get a predicted price of a property based on previous data.\n","\n","It feels awesome to know all these tools.\n","\n","From the Constructor Learning team, we thank you for your participation!\n"],"metadata":{"id":"6YUWs9bdTQQz"}},{"cell_type":"code","source":[],"metadata":{"id":"XRkp9XdtKi0W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Solutions to the exercises:\n","\n","\n","Exercise 1: \n","```\n","df['floor'] = df['floor'].fillna(\"GF\")\n","```\n","\n","Exercise 2:\n","```\n","df['last_refurbishment'] = df['last_refurbishment'].fillna(df['year_built'])\n","```\n","\n","Exercise 3:\n","```\n","latitude = zip_info[\"latitude\"]  #<-- Make this EXERCISE\n","longitude = zip_info[\"longitude\"] #<-- Make this EXERCISE\n","```\n","\n","Exercise 4:\n","```\n","fig = px.scatter(df, x=\"room_num\", y=\"price\", color='type')\n","```\n","\n","Exercise 5:\n","```\n","fig = px.scatter_mapbox(\n","    df_map, \n","    lat=\"lat\", \n","    lon=\"lon\", \n","    hover_name=\"price\", \n","    color=\"price\", \n","    zoom=7, \n","    center={\"lat\":46.8182, \"lon\":8.2275},\n",")\n","```"],"metadata":{"id":"g0TKyEN1LcjB"}}],"metadata":{"colab":{"collapsed_sections":["y9m2YIRLQ8at"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}